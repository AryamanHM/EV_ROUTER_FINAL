# -*- coding: utf-8 -*-
"""Untitled21.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11uz0p5SUwT5DzLL-rmV9saZfy9u8vnHJ
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import pickle as pkl

sns.set()

from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.pipeline import make_pipeline
from sklearn.model_selection import cross_val_score, train_test_split, KFold, GridSearchCV
from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor
from sklearn import metrics

df = pd.read_csv("data.csv")

df.head()

# Convert distance in meters to kilometers
df['Distance (km)'] = df['Total Distance (m)'] / 1000

# Save the modified DataFrame to a new CSV file
df.to_csv('modified_data.csv', index=False)

df.head()

# Load the original dataset from a CSV file
df = pd.read_csv('modified_data.csv')

# Convert seconds to hours, minutes, and seconds for 'Total Duration'
df['Total Hours'] = df['Total Duration (seconds)'] // 3600
df['Total Minutes'] = (df['Total Duration (seconds)'] % 3600) // 60
df['Total Seconds'] = df['Total Duration (seconds)'] % 60

# Convert seconds to hours, minutes, and seconds for 'Charging Duration'
df['Charging Hours'] = df['Charging Duration (seconds)'] // 3600
df['Charging Minutes'] = (df['Charging Duration (seconds)'] % 3600) // 60
df['Charging Seconds'] = df['Charging Duration (seconds)'] % 60

# Convert seconds to hours, minutes, and seconds for 'Onroad Duration'
df['Onroad Hours'] = df['Onroad Duration (seconds)'] // 3600
df['Onroad Minutes'] = (df['Onroad Duration (seconds)'] % 3600) // 60
df['Onroad Seconds'] = df['Onroad Duration (seconds)'] % 60

# Save the modified DataFrame to a new CSV file
df.to_csv('modified_dataset.csv', index=False)

df.head()

# Calculate the Price
df['Price'] = df['Distance (km)'] * 1 + df['Number of Stops'] * 231

# Save the updated DataFrame to the modified CSV file
df.to_csv('modified_dataset.csv', index=False)

df.head()

df.isnull().sum()

df["Source"].value_counts()

sns.catplot(y = "Price", x= "Source", data = df.sort_values("Price", ascending = False), kind="boxen", height = 20, aspect = 3)

# performing OneHotEncoding on Source since it's nominal categorical data
source =df[["Source"]]
source =pd.get_dummies(source, drop_first=True)
source.head()

df["Destination"].value_counts()

# destination vs price
sns.catplot(y = "Price", x= "Destination", data = df.sort_values("Price", ascending = False), kind="boxen", height = 20, aspect =3)

# performing OneHotEncoding on Destination since it's nominal categorical data
destination = df[["Destination"]]
destination = pd.get_dummies(destination, drop_first=True)
destination.head()

# total stops
print(df["Number of Stops"].value_counts())
df["Number of Stops"].unique()

final_df = pd.concat([df,source,destination], axis=1).reset_index(drop = True)

final_df

# drop date since it'll not be used as a feature
final_df.drop(["Source","Destination"], axis=1, inplace=True)

final_df

final_df.shape

final_df.isnull().sum()

final_df.columns

plt.figure(figsize = (100,100))

sns.heatmap(final_df.corr(),annot= True, cmap = "coolwarm")

plt.show()

X = final_df.drop(columns=['Price','Source Coordinates', 'Destination Coordinates'])

y = final_df["Price"]

# getting feature importance to the target variable "Price".
selection =ExtraTreesRegressor()
selection.fit(X,y)
selection.feature_importances_

# plotting graph of important features
plt.figure(figsize = (12,8))
feat_importances = pd.Series(selection.feature_importances_,index = X.columns)
feat_importances.nlargest(20).plot(kind="barh")
plt.show()

# 60% Train - 20% Val - 20% Test

X_train_or, X_test, y_train_or, y_test = train_test_split(X, y, test_size=0.2)
X_train, X_val, y_train, y_val = train_test_split(X_train_or, y_train_or, test_size=0.25)

def get_metrics(model):
    print(f'Train score {model.score(X_train, y_train)}')
    print(f'Val score {model.score(X_val, y_val)}')
    print("MAE:" , metrics.mean_absolute_error(y_val,model.predict(X_val)))
    print("MSE:" , metrics.mean_squared_error(y_val,model.predict(X_val)))
    print("RMSE:" , np.sqrt(metrics.mean_squared_error(y_val,model.predict(X_val))))

lr = LinearRegression()
lr.fit(X_train, y_train)
score = lr.score(X_val, y_val)
get_metrics(lr)

for degree in [1,2,3]:
    poly = make_pipeline(PolynomialFeatures(degree), LinearRegression())
    poly.fit(X_train, y_train)
    print("-"*20)
    print("Degree", degree)
    get_metrics(poly)

lasso_model = Lasso()
lasso_model.fit(X_train, y_train)
get_metrics(lasso_model)

ridge_model = Ridge()
ridge_model.fit(X_train, y_train)
get_metrics(ridge_model)

EN_model = ElasticNet(alpha=1)
EN_model.fit(X_train, y_train)
EN_model.score(X_val, y_val)
get_metrics(EN_model)

rf = RandomForestRegressor()
rf.fit(X_train,y_train)
get_metrics(rf)

scaler = StandardScaler()

X_train_scaled = scaler.fit_transform(X_train.values)
X_val_scaled = scaler.transform(X_val.values)
X_test_scaled = scaler.transform(X_test.values)

# function to get metrics for scaled features
def scaled_metrics(model):
    print(f'Train score {model.score(X_train_scaled, y_train)}')
    print(f'Val score {model.score(X_val_scaled, y_val)}')
    print("MAE:" , metrics.mean_absolute_error(y_val,model.predict(X_val_scaled)))
    print("MSE:" , metrics.mean_squared_error(y_val,model.predict(X_val_scaled)))
    print("RMSE:" , np.sqrt(metrics.mean_squared_error(y_val,model.predict(X_val_scaled))))


## Baseline: Linear Regression

lr = LinearRegression()
lr.fit(X_train_scaled, y_train)
score = lr.score(X_val_scaled, y_val)
print("LR")
scaled_metrics(lr)
print("-"*50)

## Polynomial

for degree in [1,2,3]:
    poly = make_pipeline(PolynomialFeatures(degree), LinearRegression())
    poly.fit(X_train, y_train)
    print("Polynomial - Degree", degree)
    scaled_metrics(poly)
    print("-"*50)

## Lasso

lasso_model = Lasso()
lasso_model.fit(X_train_scaled, y_train)
print("Lasso")
scaled_metrics(lasso_model)
print("-"*50)

## Ridge

ridge_model = Ridge()
ridge_model.fit(X_train_scaled, y_train)
print("Ridge")
scaled_metrics(ridge_model)
print("-"*50)

## ElasticNet

EN_model = ElasticNet(alpha=1)
EN_model.fit(X_train_scaled, y_train)
EN_model.score(X_val_scaled, y_val)
print("ElasticNet")
scaled_metrics(EN_model)
print("-"*50)

## Random Forest
rf = RandomForestRegressor()
rf.fit(X_train,y_train)
print("Random Forest")
scaled_metrics(rf)

# retraining the random forest model on train + val, and scoring on test

X_train_val = pd.concat([X_train,X_val])
y_train_val = pd.concat([y_train,y_val])

rf = RandomForestRegressor()
rf.fit(X_train_val,y_train_val)

print(f'Train score {rf.score(X_train_val, y_train_val)}')
print(f'Test score {rf.score(X_test, y_test)}')
print("MAE:" , metrics.mean_absolute_error(y_test,rf.predict(X_test)))
print("MSE:" , metrics.mean_squared_error(y_test,rf.predict(X_test)))
print("RMSE:" , np.sqrt(metrics.mean_squared_error(y_test,rf.predict(X_test))))

y_train_val_pred = rf.predict(X_train_val)
y_test_pred = rf.predict(X_test)

plt.scatter(y_test,y_test_pred,alpha =0.2,color="DarkBlue")
plt.title('Actual vs. Predicted  Prices')
plt.xlabel('Predicted Prices')
plt.ylabel('Actual Prices');

# randomized search CV

n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]
max_features = ['auto', 'sqrt']
max_depth = [int(x) for x in np.linspace(5, 30, num = 6)]
min_samples_split = [2, 5, 10, 15, 100]
min_samples_leaf = [1, 2, 5, 10]

# create the random grid

random_grid = {'n_estimators': n_estimators,
               'max_features': max_features,
               'max_depth': max_depth,
               'min_samples_split': min_samples_split,
               'min_samples_leaf': min_samples_leaf}

rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid,scoring='neg_mean_squared_error', n_iter = 10, cv = 5, verbose=2, n_jobs = 1)

rf_random.fit(X_train_val,y_train_val)

rf_random.best_params_

prediction = rf_random.predict(X_test)

plt.scatter(y_test,prediction,alpha =0.2,color="DarkBlue")
plt.title('Actual vs. Predicted Prices')
plt.xlabel('Predicted Prices')
plt.ylabel('Actual Prices');

print("MAE:" , metrics.mean_absolute_error(y_test,prediction))
print("MSE:" , metrics.mean_squared_error(y_test,prediction))
print("RMSE:" , np.sqrt(metrics.mean_squared_error(y_test,prediction)))

test_df = pd.DataFrame({
    "Predicted Price" : rf.predict(X_test),
    "Actual Price" : y_test,
}).reset_index(drop = True)

test_df

# save the model
file = open('rf_prediction.pkl', 'wb')
pkl.dump(rf, file)

# open the model
model = open('rf_prediction.pkl','rb')
rf_flight_prediction = pkl.load(model)

print(f'R2 score {metrics.r2_score(y_test,rf_flight_prediction.predict(X_test))}')
print("MAE:" , metrics.mean_absolute_error(y_test,rf_flight_prediction.predict(X_test)))
print("MSE:" , metrics.mean_squared_error(y_test,rf_flight_prediction.predict(X_test)))
print("RMSE:" , np.sqrt(metrics.mean_squared_error(y_test,rf_flight_prediction.predict(X_test))))

